import pandas as pd
import numpy as np
import os
import pickle
import logging
from prophet import Prophet
from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error
from model_registry import register_model
from feature_engineering import FeatureEngineer
from itertools import product
import warnings

warnings.filterwarnings('ignore')


@register_model('prophet')
class ProphetModel:
    def __init__(self, name, time_level='weekly', auto_tune=True, tuning_method='smart_grid'):
        self.name = name
        self.model = None
        self.data = None
        self.time_level = time_level
        self.auto_tune = auto_tune  # 是否自动调参
        self.tuning_method = tuning_method  # 'smart_grid' or 'bayesian' or 'time_series_cv'
        self.feature_engineer = FeatureEngineer(time_level=time_level)
        safe_name = str(name).replace('/', '_').replace('\\', '_').replace('?', '').replace('*', '').replace('[',
                                                                                                             '').replace(
            ']', '')
        self.model_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'models',
                                      safe_name.split('_')[0].capitalize())
        self.model_path = os.path.join(self.model_dir, f"{safe_name}_prophet.pkl")
        self.feature_path = os.path.join(self.model_dir, f"{safe_name}_prophet_features.pkl")
        self.metadata_path = os.path.join(self.model_dir, f"{safe_name}_prophet_metadata.pkl")
        self.best_params_path = os.path.join(self.model_dir, f"{safe_name}_best_params.pkl")
        self.absolute_mae = float('inf')
        self.max_historical_pax = None
        self.historical_pax_mean = 0
        self.recent_trend_ratio = 1.0
        self.ytd_growth_rate = 0.0
        self.historical_seasonality = None
        self.best_params = None  # 存储最优参数

    def _calculate_trend_metrics(self, df_prophet):
        """计算趋势指标"""
        df_sorted = df_prophet.sort_values('ds')

        # YTD增长率
        current_year = df_sorted['ds'].max().year
        ytd_current = df_sorted[df_sorted['ds'].dt.year == current_year]['y'].sum()
        ytd_previous = df_sorted[df_sorted['ds'].dt.year == current_year - 1]['y'].sum()

        if ytd_previous > 0:
            self.ytd_growth_rate = (ytd_current - ytd_previous) / ytd_previous
        else:
            self.ytd_growth_rate = 0.0

        # 近期趋势
        recent_6m = df_sorted.tail(26)
        previous_6m = df_sorted.iloc[-52:-26] if len(df_sorted) >= 52 else df_sorted.iloc[:26]

        recent_mean = recent_6m['y'].mean()
        previous_mean = previous_6m['y'].mean()

        if previous_mean > 0:
            self.recent_trend_ratio = recent_mean / previous_mean
        else:
            self.recent_trend_ratio = 1.0

        # 历史季节性
        if self.time_level == 'weekly':
            self.historical_seasonality = df_sorted.groupby(df_sorted['ds'].dt.isocalendar().week)['y'].mean()
        else:
            self.historical_seasonality = df_sorted.groupby(df_sorted['ds'].dt.month)['y'].mean()

        logging.info(f"{self.name} - YTD增长: {self.ytd_growth_rate:.2%}, 近期趋势: {self.recent_trend_ratio:.2%}")

    def _get_param_search_space(self):
        """根据数据特征定义智能搜索空间"""
        # 基于趋势特征缩小搜索范围
        if self.ytd_growth_rate < -0.3 or self.recent_trend_ratio < 0.7:
            # 大幅下降：重点搜索保守参数
            changepoint_range = [0.001, 0.005, 0.01, 0.02]
            seasonality_range = [8.0, 10.0, 15.0]
            logging.info(f"{self.name} 大幅下降场景，使用保守参数空间")
        elif self.ytd_growth_rate < -0.15 or self.recent_trend_ratio < 0.85:
            # 中度下降：平衡搜索
            changepoint_range = [0.01, 0.05, 0.1, 0.2]
            seasonality_range = [3.0, 5.0, 8.0, 10.0]
            logging.info(f"{self.name} 中度下降场景，使用平衡参数空间")
        elif self.ytd_growth_rate > 0.3 or self.recent_trend_ratio > 1.3:
            # 大幅增长：允许更激进的趋势捕捉
            changepoint_range = [0.05, 0.1, 0.3, 0.5]
            seasonality_range = [1.0, 3.0, 5.0]
            logging.info(f"{self.name} 大幅增长场景，使用激进参数空间")
        else:
            # 正常场景：标准搜索空间
            changepoint_range = [0.01, 0.05, 0.1, 0.2, 0.5]
            seasonality_range = [1.0, 3.0, 5.0, 10.0]
            logging.info(f"{self.name} 正常场景，使用标准参数空间")

        return {
            'changepoint_prior_scale': changepoint_range,
            'seasonality_prior_scale': seasonality_range,
            'seasonality_mode': ['additive', 'multiplicative']
        }

    def _time_series_cv_score(self, df_prophet, params, n_splits=3):
        """时间序列交叉验证评分"""
        df_sorted = df_prophet.sort_values('ds').reset_index(drop=True)
        n = len(df_sorted)

        if n < 20:  # 数据太少，只做单次验证
            n_splits = 1

        scores = []
        min_train_size = max(int(n * 0.6), 10)  # 至少60%或10条数据用于训练

        for i in range(n_splits):
            # 逐步增加训练集大小
            if n_splits == 1:
                train_size = max(int(n * 0.8), n - 5)
            else:
                train_size = min_train_size + int((n - min_train_size) * (i + 1) / (n_splits + 1))

            train = df_sorted.iloc[:train_size]
            test = df_sorted.iloc[train_size:train_size + min(5, n - train_size)]

            if len(test) == 0:
                continue

            try:
                # 训练模型
                model = Prophet(
                    yearly_seasonality=True,
                    weekly_seasonality=True,
                    daily_seasonality=False,
                    changepoint_prior_scale=params['changepoint_prior_scale'],
                    seasonality_prior_scale=params['seasonality_prior_scale'],
                    seasonality_mode=params['seasonality_mode'],
                    growth='linear'
                )

                for col in self.feature_engineer.get_feature_cols():
                    model.add_regressor(col)

                model.fit(train[['ds', 'y'] + self.feature_engineer.get_feature_cols()])

                # 预测
                future = test[['ds'] + self.feature_engineer.get_feature_cols()]
                forecast = model.predict(future)
                y_pred = forecast['yhat'].clip(lower=0)

                # 计算综合评分（MAE + MAPE，避免过度惩罚小值）
                mae = mean_absolute_error(test['y'], y_pred)
                # MAPE对小值敏感，添加epsilon避免除零
                mape = np.mean(np.abs((test['y'] - y_pred) / (test['y'] + 1e-10))) * 100

                # 检查预测是否合理（不全为0，不过度偏离历史均值）
                mean_pred = y_pred.mean()
                mean_true = test['y'].mean()
                if mean_pred == 0 or (mean_true > 0 and mean_pred / mean_true > 3):
                    # 惩罚极端预测
                    penalty = 1000
                else:
                    penalty = 0

                # 综合得分：MAE权重0.7，MAPE权重0.3
                score = 0.7 * mae + 0.3 * mape + penalty
                scores.append(score)

            except Exception as e:
                logging.warning(f"CV评分失败: {str(e)}")
                scores.append(1e6)  # 失败时给极大惩罚

        return np.mean(scores) if scores else 1e6

    def _smart_grid_search(self, df_prophet):
        """智能网格搜索：基于数据特征的自适应搜索"""
        param_space = self._get_param_search_space()

        best_score = float('inf')
        best_params = None

        # ... (existing for loop for parameter search)
        # for cp, sp, sm in param_combinations:
        #     ...

        logging.info(f"{self.name} 最优参数: {best_params}, 得分: {best_score:.2f}")

        # --- START: RECOMMENDED ADDITION ---
        if best_params is None:
            logging.warning(f"{self.name} - Hyperparameter search failed. Falling back to default parameters.")
            best_params = {
                'changepoint_prior_scale': 0.05,
                'seasonality_prior_scale': 5.0,
                'seasonality_mode': 'additive'
            }
        # --- END: RECOMMENDED ADDITION ---

        return best_params

    def _bayesian_optimization(self, df_prophet, n_iterations=15):
        """贝叶斯优化（可选，适合更大的搜索空间）"""
        try:
            from skopt import gp_minimize
            from skopt.space import Real, Categorical
        except ImportError:
            logging.warning("未安装scikit-optimize，回退到网格搜索")
            return self._smart_grid_search(df_prophet)

        param_space = self._get_param_search_space()

        # 定义搜索空间（对数尺度）
        search_space = [
            Real(np.log10(min(param_space['changepoint_prior_scale'])),
                 np.log10(max(param_space['changepoint_prior_scale'])),
                 name='changepoint_prior_scale', prior='log-uniform'),
            Real(np.log10(min(param_space['seasonality_prior_scale'])),
                 np.log10(max(param_space['seasonality_prior_scale'])),
                 name='seasonality_prior_scale', prior='log-uniform'),
            Categorical(param_space['seasonality_mode'], name='seasonality_mode')
        ]

        def objective(params_list):
            params = {
                'changepoint_prior_scale': 10 ** params_list[0],
                'seasonality_prior_scale': 10 ** params_list[1],
                'seasonality_mode': params_list[2]
            }
            return self._time_series_cv_score(df_prophet, params)

        logging.info(f"{self.name} 开始贝叶斯优化，{n_iterations} 次迭代")

        result = gp_minimize(objective, search_space, n_calls=n_iterations, random_state=42, verbose=False)

        best_params = {
            'changepoint_prior_scale': 10 ** result.x[0],
            'seasonality_prior_scale': 10 ** result.x[1],
            'seasonality_mode': result.x[2]
        }

        logging.info(f"{self.name} 最优参数: {best_params}, 得分: {result.fun:.2f}")
        return best_params

    def _find_best_params(self, df_prophet):
        """根据选择的方法找到最优参数"""
        if self.tuning_method == 'bayesian':
            return self._bayesian_optimization(df_prophet)
        elif self.tuning_method == 'smart_grid':
            return self._smart_grid_search(df_prophet)
        elif self.tuning_method == 'time_series_cv':
            # 使用Prophet内置的交叉验证（较慢但更准确）
            return self._smart_grid_search(df_prophet)  # 简化实现
        else:
            return self._smart_grid_search(df_prophet)

    def fit(self, data, mode='full_retrain'):
        self.data = data
        date_col = next(col for col in ['Correct Event Time', 'Date', 'WeekStart', 'MonthStart'] if col in data.columns)

        if mode == 'no_train' and os.path.exists(self.model_path):
            logging.info(f"{self.name} 载入已有模型")
            with open(self.model_path, 'rb') as f:
                self.model = pickle.load(f)
            with open(self.feature_path, 'rb') as f:
                self.feature_engineer.feature_cols = pickle.load(f)
            with open(self.metadata_path, 'rb') as f:
                metadata = pickle.load(f)
                self.ytd_growth_rate = metadata['ytd_growth_rate']
                self.recent_trend_ratio = metadata['recent_trend_ratio']
                self.historical_seasonality = metadata['historical_seasonality']
                self.historical_pax_mean = metadata['historical_pax_mean']
                self.max_historical_pax = metadata['max_historical_pax']
            if os.path.exists(self.best_params_path):
                with open(self.best_params_path, 'rb') as f:
                    self.best_params = pickle.load(f)
            return self

        processed_df = self.feature_engineer.preprocess_features(data, date_col, is_training=True)
        processed_df[date_col] = pd.to_datetime(processed_df[date_col])

        df_prophet = processed_df.rename(columns={date_col: 'ds', 'Actual Pax': 'y'})
        df_prophet['y'] = pd.to_numeric(df_prophet['y'], errors='coerce').clip(lower=0)
        df_prophet = df_prophet.dropna(subset=['y'])

        self.historical_pax_mean = df_prophet['y'].mean()
        self.max_historical_pax = df_prophet['y'].max()

        if len(df_prophet) < 5:
            logging.warning(f"{self.name} 数据不足，无法训练")
            self.model = None
            self.absolute_mae = float('inf')
            return self

        # 计算趋势指标
        self._calculate_trend_metrics(df_prophet)

        # 自动调参
        if self.auto_tune:
            self.best_params = self._find_best_params(df_prophet)
        else:
            # 使用默认参数或已保存的参数
            if os.path.exists(self.best_params_path):
                with open(self.best_params_path, 'rb') as f:
                    self.best_params = pickle.load(f)
            else:
                self.best_params = {
                    'changepoint_prior_scale': 0.05,
                    'seasonality_prior_scale': 5.0,
                    'seasonality_mode': 'additive'
                }

        # 使用最优参数训练最终模型
        self.model = Prophet(
            yearly_seasonality=True,
            weekly_seasonality=True,
            daily_seasonality=False,
            changepoint_prior_scale=self.best_params['changepoint_prior_scale'],
            seasonality_prior_scale=self.best_params['seasonality_prior_scale'],
            seasonality_mode=self.best_params['seasonality_mode'],
            growth='linear'
        )

        for col in self.feature_engineer.get_feature_cols():
            self.model.add_regressor(col)

        try:
            self.model.fit(df_prophet[['ds', 'y'] + self.feature_engineer.get_feature_cols()])
        except Exception as e:
            logging.error(f"{self.name} 训练失败: {str(e)}")
            self.model = None
            self.absolute_mae = float('inf')
            return self

        # 计算MAE
        train_size = max(int(len(df_prophet) * 0.8), len(df_prophet) - 5)
        train_df, test_df = df_prophet[:train_size], df_prophet[train_size:]
        if not test_df.empty:
            try:
                future = test_df[['ds'] + self.feature_engineer.get_feature_cols()]
                y_pred = self.model.predict(future)['yhat'].clip(lower=0)
                self.absolute_mae = mean_absolute_error(test_df['y'], y_pred)
                logging.info(f"{self.name} MAE: {self.absolute_mae:.2f}")
            except Exception as e:
                logging.error(f"MAE 计算失败: {str(e)}")
                self.absolute_mae = float('inf')

        # 保存所有内容
        os.makedirs(self.model_dir, exist_ok=True)
        with open(self.model_path, 'wb') as f:
            pickle.dump(self.model, f)
        with open(self.feature_path, 'wb') as f:
            pickle.dump(self.feature_engineer.get_feature_cols(), f)
        with open(self.metadata_path, 'wb') as f:
            pickle.dump({
                'ytd_growth_rate': self.ytd_growth_rate,
                'recent_trend_ratio': self.recent_trend_ratio,
                'historical_seasonality': self.historical_seasonality,
                'historical_pax_mean': self.historical_pax_mean,
                'max_historical_pax': self.max_historical_pax
            }, f)
        with open(self.best_params_path, 'wb') as f:
            pickle.dump(self.best_params, f)

        return self

    def _apply_intelligent_floor(self, predictions, dates):
        """智能下界保护"""
        last_year_data = self.data.copy()
        date_col = next(
            col for col in ['Correct Event Time', 'Date', 'WeekStart', 'MonthStart'] if col in last_year_data.columns)
        last_year_data[date_col] = pd.to_datetime(last_year_data[date_col])

        adjusted_predictions = []
        for i, pred_date in enumerate(dates):
            raw_pred = predictions.iloc[i]

            if self.time_level == 'weekly':
                last_year_date = pred_date - pd.DateOffset(years=1)
                mask = (last_year_data[date_col] >= last_year_date - pd.Timedelta(days=7)) & \
                       (last_year_data[date_col] <= last_year_date + pd.Timedelta(days=7))
            else:
                last_year_date = pred_date - pd.DateOffset(years=1)
                mask = (last_year_data[date_col].dt.month == last_year_date.month) & \
                       (last_year_data[date_col].dt.year == last_year_date.year)

            last_year_value = last_year_data[mask]['Actual Pax'].mean() if mask.any() else self.historical_pax_mean

            # 触发条件：预测 < 去年同期20% 且去年同期有值
            if raw_pred < last_year_value * 0.2 and last_year_value > 0:
                smoothed_growth = 0.6 * self.ytd_growth_rate + 0.4 * (self.recent_trend_ratio - 1)
                smoothed_growth = max(smoothed_growth, -0.4)  # 最多下降40%

                if self.historical_seasonality is not None:
                    if self.time_level == 'weekly':
                        week_num = pred_date.isocalendar()[1]
                        seasonal_factor = self.historical_seasonality.get(week_num, 1.0) / self.historical_pax_mean
                    else:
                        month_num = pred_date.month
                        seasonal_factor = self.historical_seasonality.get(month_num, 1.0) / self.historical_pax_mean
                else:
                    seasonal_factor = 1.0

                baseline = last_year_value * (1 + smoothed_growth) * seasonal_factor
                adjusted_pred = min(max(raw_pred, baseline), last_year_value * 1.2)

                logging.debug(f"{self.name} {pred_date.date()}: 原始={raw_pred:.1f}, 调整后={adjusted_pred:.1f}")
                adjusted_predictions.append(adjusted_pred)
            else:
                adjusted_predictions.append(raw_pred)

        return pd.Series(adjusted_predictions)

    def predict(self, start_date, end_date, output_agg_level):
        freq = {'daily': 'D', 'weekly': 'W-MON', 'monthly': 'MS'}[output_agg_level]
        dates = pd.date_range(start=start_date, end=end_date, freq=freq)

        if not self.model:
            logging.warning(f"{self.name} 无模型")
            return pd.DataFrame({'Dates': dates, 'Predictions': np.zeros(len(dates))})

        date_col = next(
            col for col in ['Correct Event Time', 'Date', 'WeekStart', 'MonthStart'] if col in self.data.columns)

        try:
            special_events = pd.read_excel(
                os.path.join(os.path.dirname(os.path.abspath(__file__)), 'Spreadsheets Source', 'Special Event.xlsx'),
                parse_dates=['Date'])
            special_events = special_events[
                (special_events['Date'] >= start_date) & (special_events['Date'] <= end_date)]
            special_events_agg = special_events.groupby('Date').agg({
                'Special Event': lambda x: ';'.join(str(i) for i in x if pd.notna(i)),
                'Special Event City': lambda x: ';'.join(str(i) for i in x if pd.notna(i)),
                'Event Type': lambda x: ';'.join(str(i) for i in x if pd.notna(i)),
                'Impact Scale': 'mean'
            }).reset_index()
        except FileNotFoundError:
            special_events_agg = pd.DataFrame({
                'Date': dates,
                'Special Event': [''] * len(dates),
                'Special Event City': [''] * len(dates),
                'Event Type': [''] * len(dates),
                'Impact Scale': [1.0] * len(dates)
            })

        future_df = pd.DataFrame({date_col: dates})
        future_df = future_df.merge(special_events_agg, left_on=date_col, right_on='Date', how='left')
        future_df.fillna({'Special Event': '', 'Special Event City': '', 'Event Type': '', 'Impact Scale': 1.0},
                         inplace=True)

        future_df = self.feature_engineer.preprocess_features(future_df, date_col, is_training=False)
        future_df[date_col] = pd.to_datetime(future_df[date_col])

        for col in self.feature_engineer.get_feature_cols():
            if col not in future_df.columns:
                future_df[col] = 0

        future_prophet = future_df.rename(columns={date_col: 'ds'})
        try:
            forecast = self.model.predict(future_prophet[['ds'] + self.feature_engineer.get_feature_cols()])
            raw_predictions = forecast['yhat'].clip(lower=0)
            adjusted_predictions = self._apply_intelligent_floor(raw_predictions, dates)
            final_predictions = adjusted_predictions.clip(lower=0)
        except Exception as e:
            logging.error(f"预测失败: {str(e)}")
            return pd.DataFrame({'Dates': dates, 'Predictions': np.zeros(len(dates))})

        return pd.DataFrame({'Dates': dates, 'Predictions': final_predictions})
