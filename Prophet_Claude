import pandas as pd
import numpy as np
import os
import pickle
import logging
from prophet import Prophet
from sklearn.metrics import mean_absolute_error
from model_registry import register_model
from feature_engineering import FeatureEngineer

@register_model('prophet')
class ProphetModel:
    def __init__(self, name, time_level='weekly'):
        self.name = name
        self.model = None
        self.data = None
        self.time_level = time_level
        self.feature_engineer = FeatureEngineer(time_level=time_level)
        safe_name = str(name).replace('/', '_').replace('\\', '_').replace('?', '').replace('*', '').replace('[', '').replace(']', '')
        self.model_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'models', safe_name.split('_')[0].capitalize())
        self.model_path = os.path.join(self.model_dir, f"{safe_name}_prophet.pkl")
        self.feature_path = os.path.join(self.model_dir, f"{safe_name}_prophet_features.pkl")
        self.metadata_path = os.path.join(self.model_dir, f"{safe_name}_prophet_metadata.pkl")
        self.absolute_mae = float('inf')
        self.max_historical_pax = None
        self.historical_pax_mean = 0
        self.recent_trend_ratio = 1.0  # 近期趋势比率
        self.ytd_growth_rate = 0.0  # YTD增长率
        self.historical_seasonality = None  # 历史季节性模式

    def _calculate_trend_metrics(self, df_prophet):
        """计算趋势指标，用于智能调整"""
        df_sorted = df_prophet.sort_values('ds')
        
        # 计算YTD增长率（今年vs去年同期）
        current_year = df_sorted['ds'].max().year
        ytd_current = df_sorted[df_sorted['ds'].dt.year == current_year]['y'].sum()
        ytd_previous = df_sorted[df_sorted['ds'].dt.year == current_year - 1]['y'].sum()
        
        if ytd_previous > 0:
            self.ytd_growth_rate = (ytd_current - ytd_previous) / ytd_previous
        else:
            self.ytd_growth_rate = 0.0
        
        # 计算近期趋势（最近6个月vs之前6个月）
        recent_6m = df_sorted.tail(26)  # 约6个月的周数据
        previous_6m = df_sorted.iloc[-52:-26] if len(df_sorted) >= 52 else df_sorted.iloc[:26]
        
        recent_mean = recent_6m['y'].mean()
        previous_mean = previous_6m['y'].mean()
        
        if previous_mean > 0:
            self.recent_trend_ratio = recent_mean / previous_mean
        else:
            self.recent_trend_ratio = 1.0
        
        # 提取历史季节性模式（按周或月的平均值）
        if self.time_level == 'weekly':
            self.historical_seasonality = df_sorted.groupby(df_sorted['ds'].dt.isocalendar().week)['y'].mean()
        else:
            self.historical_seasonality = df_sorted.groupby(df_sorted['ds'].dt.month)['y'].mean()
        
        logging.info(f"{self.name} - YTD增长率: {self.ytd_growth_rate:.2%}, 近期趋势比率: {self.recent_trend_ratio:.2%}")

    def _get_adaptive_parameters(self):
        """根据数据特征自适应调整参数"""
        # 基础参数
        base_changepoint = 0.05
        base_seasonality = 5.0
        
        # 如果下降严重（YTD或近期趋势下降超过30%），减小changepoint敏感度
        if self.ytd_growth_rate < -0.3 or self.recent_trend_ratio < 0.7:
            changepoint_prior_scale = 0.001  # 大幅降低，防止趋势过度下降
            seasonality_prior_scale = 10.0   # 增强季节性权重
            logging.info(f"{self.name} 检测到大幅下降，使用保守趋势参数")
        elif self.ytd_growth_rate < -0.15 or self.recent_trend_ratio < 0.85:
            changepoint_prior_scale = 0.01   # 适度降低
            seasonality_prior_scale = 8.0
            logging.info(f"{self.name} 检测到中度下降，使用平衡参数")
        else:
            changepoint_prior_scale = base_changepoint
            seasonality_prior_scale = base_seasonality
        
        return changepoint_prior_scale, seasonality_prior_scale

    def fit(self, data, mode='full_retrain'):
        self.data = data
        date_col = next(col for col in ['Correct Event Time', 'Date', 'WeekStart', 'MonthStart'] if col in data.columns)

        if mode == 'no_train' and os.path.exists(self.model_path):
            logging.info(f"{self.name} 载入已有模型: {self.model_path}")
            with open(self.model_path, 'rb') as f:
                self.model = pickle.load(f)
            with open(self.feature_path, 'rb') as f:
                self.feature_engineer.feature_cols = pickle.load(f)
            with open(self.metadata_path, 'rb') as f:
                metadata = pickle.load(f)
                self.ytd_growth_rate = metadata['ytd_growth_rate']
                self.recent_trend_ratio = metadata['recent_trend_ratio']
                self.historical_seasonality = metadata['historical_seasonality']
                self.historical_pax_mean = metadata['historical_pax_mean']
                self.max_historical_pax = metadata['max_historical_pax']
            return self

        processed_df = self.feature_engineer.preprocess_features(data, date_col, is_training=True)
        processed_df[date_col] = pd.to_datetime(processed_df[date_col])

        df_prophet = processed_df.rename(columns={date_col: 'ds', 'Actual Pax': 'y'})
        df_prophet['y'] = pd.to_numeric(df_prophet['y'], errors='coerce').clip(lower=0)
        df_prophet = df_prophet.dropna(subset=['y'])

        self.historical_pax_mean = df_prophet['y'].mean()
        self.max_historical_pax = df_prophet['y'].max()

        if len(df_prophet) < 5:
            logging.warning(f"{self.name} 数据不足（{len(df_prophet)} 行），无法训练")
            self.model = None
            self.absolute_mae = float('inf')
            return self

        # 计算趋势指标
        self._calculate_trend_metrics(df_prophet)
        
        # 获取自适应参数
        changepoint_prior_scale, seasonality_prior_scale = self._get_adaptive_parameters()

        self.model = Prophet(
            yearly_seasonality=True,
            weekly_seasonality=True,
            daily_seasonality=False,
            changepoint_prior_scale=changepoint_prior_scale,
            seasonality_prior_scale=seasonality_prior_scale,
            growth='linear'  # 保持linear，但通过changepoint控制
        )

        for col in self.feature_engineer.get_feature_cols():
            self.model.add_regressor(col)

        try:
            self.model.fit(df_prophet[['ds', 'y'] + self.feature_engineer.get_feature_cols()])
        except Exception as e:
            logging.error(f"{self.name} 训练失败: {str(e)}")
            self.model = None
            self.absolute_mae = float('inf')
            return self

        train_size = max(int(len(df_prophet) * 0.8), len(df_prophet) - 5)
        train_df, test_df = df_prophet[:train_size], df_prophet[train_size:]
        if not test_df.empty:
            try:
                future = test_df[['ds'] + self.feature_engineer.get_feature_cols()]
                y_pred = self.model.predict(future)['yhat'].clip(lower=0)
                self.absolute_mae = mean_absolute_error(test_df['y'], y_pred)
                logging.info(f"{self.name} MAE: {self.absolute_mae:.2f}")
            except Exception as e:
                logging.error(f"MAE 计算失败: {str(e)}")
                self.absolute_mae = float('inf')

        # 保存模型和元数据
        os.makedirs(self.model_dir, exist_ok=True)
        with open(self.model_path, 'wb') as f:
            pickle.dump(self.model, f)
        with open(self.feature_path, 'wb') as f:
            pickle.dump(self.feature_engineer.get_feature_cols(), f)
        with open(self.metadata_path, 'wb') as f:
            pickle.dump({
                'ytd_growth_rate': self.ytd_growth_rate,
                'recent_trend_ratio': self.recent_trend_ratio,
                'historical_seasonality': self.historical_seasonality,
                'historical_pax_mean': self.historical_pax_mean,
                'max_historical_pax': self.max_historical_pax
            }, f)

        return self

    def _apply_intelligent_floor(self, predictions, dates):
        """智能下界保护：保持季节性模式但避免为0"""
        # 获取去年同期数据作为参考
        last_year_data = self.data.copy()
        date_col = next(col for col in ['Correct Event Time', 'Date', 'WeekStart', 'MonthStart'] if col in last_year_data.columns)
        last_year_data[date_col] = pd.to_datetime(last_year_data[date_col])
        
        # 为每个预测日期找到去年同期的值
        adjusted_predictions = []
        for i, pred_date in enumerate(dates):
            raw_pred = predictions.iloc[i]
            
            # 查找去年同期（同一周/月）
            if self.time_level == 'weekly':
                last_year_date = pred_date - pd.DateOffset(years=1)
                # 允许±7天的窗口
                mask = (last_year_data[date_col] >= last_year_date - pd.Timedelta(days=7)) & \
                       (last_year_data[date_col] <= last_year_date + pd.Timedelta(days=7))
            else:
                last_year_date = pred_date - pd.DateOffset(years=1)
                mask = (last_year_data[date_col].dt.month == last_year_date.month) & \
                       (last_year_data[date_col].dt.year == last_year_date.year)
            
            last_year_value = last_year_data[mask]['Actual Pax'].mean() if mask.any() else self.historical_pax_mean
            
            # 如果原始预测太低（<去年同期的20%），则应用智能修正
            if raw_pred < last_year_value * 0.2 and last_year_value > 0:
                # 使用平滑的增长率（取YTD和近期趋势的加权平均，并限制下降幅度）
                smoothed_growth = 0.6 * self.ytd_growth_rate + 0.4 * (self.recent_trend_ratio - 1)
                smoothed_growth = max(smoothed_growth, -0.4)  # 最多下降40%
                
                # 应用历史季节性模式
                if self.historical_seasonality is not None:
                    if self.time_level == 'weekly':
                        week_num = pred_date.isocalendar()[1]
                        seasonal_factor = self.historical_seasonality.get(week_num, 1.0) / self.historical_pax_mean
                    else:
                        month_num = pred_date.month
                        seasonal_factor = self.historical_seasonality.get(month_num, 1.0) / self.historical_pax_mean
                else:
                    seasonal_factor = 1.0
                
                # 基础值 = 去年同期 * (1 + 平滑增长率) * 季节性因子
                baseline = last_year_value * (1 + smoothed_growth) * seasonal_factor
                
                # 在原始预测和基线之间取最大值，但不超过去年同期的120%
                adjusted_pred = min(max(raw_pred, baseline), last_year_value * 1.2)
                
                logging.debug(f"{self.name} {pred_date.date()}: 原始={raw_pred:.1f}, 去年同期={last_year_value:.1f}, "
                             f"调整后={adjusted_pred:.1f}")
                adjusted_predictions.append(adjusted_pred)
            else:
                adjusted_predictions.append(raw_pred)
        
        return pd.Series(adjusted_predictions)

    def predict(self, start_date, end_date, output_agg_level):
        freq = {'daily': 'D', 'weekly': 'W-MON', 'monthly': 'MS'}[output_agg_level]
        dates = pd.date_range(start=start_date, end=end_date, freq=freq)

        if not self.model:
            logging.warning(f"{self.name} 无模型，返回零预测")
            return pd.DataFrame({'Dates': dates, 'Predictions': np.zeros(len(dates))})

        date_col = next(col for col in ['Correct Event Time', 'Date', 'WeekStart', 'MonthStart'] if col in self.data.columns)

        try:
            special_events = pd.read_excel(os.path.join(os.path.dirname(os.path.abspath(__file__)), 'Spreadsheets Source', 'Special Event.xlsx'), parse_dates=['Date'])
            special_events = special_events[(special_events['Date'] >= start_date) & (special_events['Date'] <= end_date)]
            special_events_agg = special_events.groupby('Date').agg({
                'Special Event': lambda x: ';'.join(str(i) for i in x if pd.notna(i)),
                'Special Event City': lambda x: ';'.join(str(i) for i in x if pd.notna(i)),
                'Event Type': lambda x: ';'.join(str(i) for i in x if pd.notna(i)),
                'Impact Scale': 'mean'
            }).reset_index()
            logging.info(f"预测期间特殊事件数: {len(special_events_agg)}")
        except FileNotFoundError:
            special_events_agg = pd.DataFrame({
                'Date': dates,
                'Special Event': [''] * len(dates),
                'Special Event City': [''] * len(dates),
                'Event Type': [''] * len(dates),
                'Impact Scale': [1.0] * len(dates)
            })
            logging.warning("找不到 Special Event.xlsx，假设无特殊事件")

        future_df = pd.DataFrame({date_col: dates})
        future_df = future_df.merge(special_events_agg, left_on=date_col, right_on='Date', how='left')
        future_df.fillna({'Special Event': '', 'Special Event City': '', 'Event Type': '', 'Impact Scale': 1.0}, inplace=True)

        future_df = self.feature_engineer.preprocess_features(future_df, date_col, is_training=False)
        future_df[date_col] = pd.to_datetime(future_df[date_col])

        for col in self.feature_engineer.get_feature_cols():
            if col not in future_df.columns:
                future_df[col] = 0

        future_prophet = future_df.rename(columns={date_col: 'ds'})
        try:
            forecast = self.model.predict(future_prophet[['ds'] + self.feature_engineer.get_feature_cols()])
            raw_predictions = forecast['yhat'].clip(lower=0)
            
            # 应用智能下界保护
            adjusted_predictions = self._apply_intelligent_floor(raw_predictions, dates)
            
            # 最终确保非负
            final_predictions = adjusted_predictions.clip(lower=0)
            
        except Exception as e:
            logging.error(f"预测失败: {str(e)}")
            return pd.DataFrame({'Dates': dates, 'Predictions': np.zeros(len(dates))})

        return pd.DataFrame({'Dates': dates, 'Predictions': final_predictions})
