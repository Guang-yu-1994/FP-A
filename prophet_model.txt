import pandas as pd
import numpy as np
import os
import pickle
import logging
from prophet import Prophet
from sklearn.metrics import mean_absolute_error
from model_registry import register_model
from feature_engineering import FeatureEngineer

@register_model('prophet')
class ProphetModel:
    def __init__(self, name, time_level='weekly'):
        self.name = name
        self.model = None
        self.data = None
        self.time_level = time_level
        self.feature_engineer = FeatureEngineer(time_level=time_level)
        safe_name = str(name).replace('/', '_').replace('\\', '_').replace('?', '').replace('*', '').replace('[', '').replace(']', '')
        self.model_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'models', safe_name.split('_')[0].capitalize())
        self.model_path = os.path.join(self.model_dir, f"{safe_name}_prophet.pkl")
        self.feature_path = os.path.join(self.model_dir, f"{safe_name}_prophet_features.pkl")
        self.metadata_path = os.path.join(self.model_dir, f"{safe_name}_prophet_metadata.pkl")
        self.absolute_mae = float('inf')
        self.max_historical_pax = None
        self.historical_pax_mean = 0
        self.recent_trend_ratio = 1.0
        self.ytd_growth_rate = 0.0
        self.historical_seasonality = None

    def _calculate_trend_metrics(self, df_prophet):
        """计算历史指标，用于下限保护和fallback"""
        df_sorted = df_prophet.sort_values('ds')
        self.historical_pax_mean = df_sorted['y'].mean()
        self.max_historical_pax = df_sorted['y'].max()

        # YTD增长率（用于下限保护）
        current_year = df_sorted['ds'].max().year
        ytd_current = df_sorted[df_sorted['ds'].dt.year == current_year]['y'].sum()
        ytd_previous = df_sorted[df_sorted['ds'].dt.year == current_year - 1]['y'].sum()
        self.ytd_growth_rate = (ytd_current - ytd_previous) / ytd_previous if ytd_previous > 0 else 0.0

        # 近期趋势（用于下限保护）
        recent_6m = df_sorted.tail(26)
        previous_6m = df_sorted.iloc[-52:-26] if len(df_sorted) >= 52 else df_sorted.iloc[:26]
        recent_mean = recent_6m['y'].median()
        previous_mean = previous_6m['y'].median()
        self.recent_trend_ratio = recent_mean / previous_mean if previous_mean > 0 else 1.0

        # 历史季节性（用于下限保护和fallback）
        if self.time_level == 'weekly':
            self.historical_seasonality = df_sorted.groupby(df_sorted['ds'].dt.isocalendar().week)['y'].mean()
        else:
            self.historical_seasonality = df_sorted.groupby(df_sorted['ds'].dt.month)['y'].mean()

        logging.info(f"{self.name} - YTD增长: {self.ytd_growth_rate:.2%}, 近期趋势: {self.recent_trend_ratio:.2%}, 历史平均Pax: {self.historical_pax_mean:.1f}")

    def fit(self, data, mode='full_retrain'):
        self.data = data
        date_col = next(col for col in ['Correct Event Time', 'Date', 'WeekStart', 'MonthStart'] if col in data.columns)

        if mode == 'no_train' and os.path.exists(self.model_path):
            logging.info(f"{self.name} 载入已有模型")
            with open(self.model_path, 'rb') as f:
                self.model = pickle.load(f)
            with open(self.feature_path, 'rb') as f:
                self.feature_engineer.feature_cols = pickle.load(f)
            with open(self.metadata_path, 'rb') as f:
                metadata = pickle.load(f)
                self.ytd_growth_rate = metadata['ytd_growth_rate']
                self.recent_trend_ratio = metadata['recent_trend_ratio']
                self.historical_seasonality = metadata['historical_seasonality']
                self.historical_pax_mean = metadata['historical_pax_mean']
                self.max_historical_pax = metadata['max_historical_pax']
            return self

        processed_df = self.feature_engineer.preprocess_features(data, date_col, is_training=True)
        processed_df[date_col] = pd.to_datetime(processed_df[date_col])

        df_prophet = processed_df.rename(columns={date_col: 'ds', 'Actual Pax': 'y'})
        df_prophet['y'] = pd.to_numeric(df_prophet['y'], errors='coerce').clip(lower=0)
        df_prophet = df_prophet.dropna(subset=['y'])

        if len(df_prophet) < 5:
            logging.warning(f"{self.name} 数据不足，无法训练")
            self.model = None
            self.absolute_mae = float('inf')
            return self

        self._calculate_trend_metrics(df_prophet)

        self.model = Prophet(
            yearly_seasonality=True,
            weekly_seasonality=True,
            daily_seasonality=False,
            changepoint_prior_scale=0.05,
            seasonality_prior_scale=5.0,
            seasonality_mode='additive',
            growth='linear'
        )

        for col in self.feature_engineer.get_feature_cols():
            self.model.add_regressor(col)

        try:
            self.model.fit(df_prophet[['ds', 'y'] + self.feature_engineer.get_feature_cols()])
        except Exception as e:
            logging.error(f"{self.name} 训练失败: {str(e)}")
            self.model = None
            self.absolute_mae = float('inf')
            return self

        train_size = max(int(len(df_prophet) * 0.8), len(df_prophet) - 5)
        train_df, test_df = df_prophet[:train_size], df_prophet[train_size:]
        if not test_df.empty:
            try:
                future = test_df[['ds'] + self.feature_engineer.get_feature_cols()]
                y_pred = self.model.predict(future)['yhat'].clip(lower=0)
                self.absolute_mae = mean_absolute_error(test_df['y'], y_pred)
                logging.info(f"{self.name} MAE: {self.absolute_mae:.2f}")
            except Exception as e:
                logging.error(f"MAE 计算失败: {str(e)}")
                self.absolute_mae = float('inf')

        os.makedirs(self.model_dir, exist_ok=True)
        with open(self.model_path, 'wb') as f:
            pickle.dump(self.model, f)
        with open(self.feature_path, 'wb') as f:
            pickle.dump(self.feature_engineer.get_feature_cols(), f)
        with open(self.metadata_path, 'wb') as f:
            pickle.dump({
                'ytd_growth_rate': self.ytd_growth_rate,
                'recent_trend_ratio': self.recent_trend_ratio,
                'historical_seasonality': self.historical_seasonality,
                'historical_pax_mean': self.historical_pax_mean,
                'max_historical_pax': self.max_historical_pax
            }, f)

        return self

    def _get_last_year_value(self, pred_date, last_year_data, date_col):
        """封装去年同期值查找逻辑"""
        has_last_year_data = False
        last_year_value = 0.0

        if self.time_level == 'weekly':
            pred_week = pred_date.isocalendar().week
            last_year = pred_date.year - 1
            mask = (last_year_data[date_col].dt.year == last_year) & \
                   (last_year_data[date_col].dt.isocalendar().week == pred_week)
        elif self.time_level == 'monthly':
            pred_month = pred_date.month
            last_year = pred_date.year - 1
            mask = (last_year_data[date_col].dt.year == last_year) & \
                   (last_year_data[date_col].dt.month == pred_month)
        else:  # daily
            last_year_date = pred_date - pd.DateOffset(years=1)
            mask = (last_year_data[date_col] >= last_year_date - pd.Timedelta(days=3)) & \
                   (last_year_data[date_col] <= last_year_date + pd.Timedelta(days=3))

        has_last_year_data = mask.any()
        if has_last_year_data:
            last_year_value = last_year_data[mask]['Actual Pax'].mean()
            logging.debug(f"{self.name} {pred_date.date()} [去年同期查找]: 找到数据，值为 {last_year_value:.1f}")
        else:
            logging.debug(f"{self.name} {pred_date.date()} [去年同期查找]: 未找到数据，强制值为 0.0")
            last_year_value = 0.0

        return last_year_value

    def _apply_low_season_cap(self, raw_pred, last_year_value, pred_date):
        """封装淡季上限规则：Q1/Q4 预测不超过去年同期2倍"""
        adjusted_pred = raw_pred
        is_low_season = pred_date.month in [1, 2, 3, 10, 11, 12]
        logging.debug(f"{self.name} {pred_date.date()} [淡季判断]: {'是' if is_low_season else '否'} (月份={pred_date.month})")

        if is_low_season and raw_pred > last_year_value * 2.0:
            adjusted_pred = last_year_value * 2.0
            logging.debug(f"{self.name} {pred_date.date()} [淡季封顶规则]: 触发，上限调整 - 原始={raw_pred:.1f} > {last_year_value * 2.0:.1f}，调整为 {adjusted_pred:.1f} (去年同期={last_year_value:.1f})")
        else:
            logging.debug(f"{self.name} {pred_date.date()} [淡季封顶规则]: 未触发")

        return adjusted_pred

    def _apply_low_prediction_floor(self, adjusted_pred, last_year_value, pred_date):
        """封装过低预测下限保护：避免极端下降为0"""
        if adjusted_pred < last_year_value * 0.2 and last_year_value > 0:
            smoothed_growth = 0.6 * self.ytd_growth_rate + 0.4 * (self.recent_trend_ratio - 1)
            smoothed_growth = max(smoothed_growth, -0.4)  # 避免过度负增长

            if self.historical_seasonality is not None:
                if self.time_level == 'weekly':
                    week_num = pred_date.isocalendar()[1]
                    seasonal_factor = self.historical_seasonality.get(week_num, 1.0) / (self.historical_pax_mean + 1e-9)
                else:
                    month_num = pred_date.month
                    seasonal_factor = self.historical_seasonality.get(month_num, 1.0) / (self.historical_pax_mean + 1e-9)
            else:
                seasonal_factor = 1.0

            baseline = last_year_value * (1 + smoothed_growth) * seasonal_factor
            adjusted_pred = min(max(adjusted_pred, baseline), last_year_value * 1.2)
            logging.debug(f"{self.name} {pred_date.date()} [下限保护规则]: 触发，下限调整 - 原始={adjusted_pred:.1f} -> {adjusted_pred:.1f} (基线={baseline:.1f}, 增长率={smoothed_growth:.2%})")
        else:
            logging.debug(f"{self.name} {pred_date.date()} [下限保护规则]: 未触发")

        return adjusted_pred

    def _apply_intelligent_floor(self, predictions, dates):
        """主调整函数：先淡季上限，再过低下限"""
        last_year_data = self.data.copy()
        date_col = next(col for col in ['Correct Event Time', 'Date', 'WeekStart', 'MonthStart'] if col in last_year_data.columns)
        last_year_data[date_col] = pd.to_datetime(last_year_data[date_col])

        adjusted_predictions = []
        for i, pred_date in enumerate(dates):
            raw_pred = predictions.iloc[i]
            logging.debug(f"{self.name} {pred_date.date()} [预测开始]: 原始预测={raw_pred:.1f}")

            last_year_value = self._get_last_year_value(pred_date, last_year_data, date_col)

            # 先淡季上限
            adjusted_pred = self._apply_low_season_cap(raw_pred, last_year_value, pred_date)

            # 再过低下限（避免极端0）
            adjusted_pred = self._apply_low_prediction_floor(adjusted_pred, last_year_value, pred_date)

            adjusted_predictions.append(adjusted_pred)

        logging.debug(f"{self.name} [调整结果]: 原始预测均值={predictions.mean():.1f}, 调整后均值={pd.Series(adjusted_predictions).mean():.1f}")
        return pd.Series(adjusted_predictions)

    def predict(self, start_date, end_date, output_agg_level):
        freq = {'daily': 'D', 'weekly': 'W-MON', 'monthly': 'MS'}[output_agg_level]
        dates = pd.date_range(start=start_date, end=end_date, freq=freq)

        if not self.model:
            logging.warning(f"{self.name} 无模型")
            return pd.DataFrame({'Dates': dates, 'Predictions': np.zeros(len(dates))})

        date_col = next(
            col for col in ['Correct Event Time', 'Date', 'WeekStart', 'MonthStart'] if col in self.data.columns)

        try:
            special_events = pd.read_excel(
                os.path.join(os.path.dirname(os.path.abspath(__file__)), 'Spreadsheets Source', 'Special Event.xlsx'),
                parse_dates=['Date'])
            special_events = special_events[
                (special_events['Date'] >= start_date) & (special_events['Date'] <= end_date)]
            special_events_agg = special_events.groupby('Date').agg({
                'Special Event': lambda x: ';'.join(str(i) for i in x if pd.notna(i)),
                'Special Event City': lambda x: ';'.join(str(i) for i in x if pd.notna(i)),
                'Event Type': lambda x: ';'.join(str(i) for i in x if pd.notna(i)),
                'Impact Scale': 'mean'
            }).reset_index()
        except FileNotFoundError:
            special_events_agg = pd.DataFrame({
                'Date': dates,
                'Special Event': [''] * len(dates),
                'Special Event City': [''] * len(dates),
                'Event Type': [''] * len(dates),
                'Impact Scale': [1.0] * len(dates)
            })

        future_df = pd.DataFrame({date_col: dates})
        future_df = future_df.merge(special_events_agg, left_on=date_col, right_on='Date', how='left')
        future_df.fillna({'Special Event': '', 'Special Event City': '', 'Event Type': '', 'Impact Scale': 1.0}, inplace=True)

        future_df = self.feature_engineer.preprocess_features(future_df, date_col, is_training=False)
        future_df[date_col] = pd.to_datetime(future_df[date_col])

        for col in self.feature_engineer.get_feature_cols():
            if col not in future_df.columns:
                future_df[col] = 0

        future_prophet = future_df.rename(columns={date_col: 'ds'})
        try:
            forecast = self.model.predict(future_prophet[['ds'] + self.feature_engineer.get_feature_cols()])
            raw_predictions = forecast['yhat'].clip(lower=0)
            adjusted_predictions = self._apply_intelligent_floor(raw_predictions, dates)
            final_predictions = adjusted_predictions.clip(lower=0)
        except Exception as e:
            logging.error(f"预测失败: {str(e)}")
            return pd.DataFrame({'Dates': dates, 'Predictions': np.zeros(len(dates))})

        return pd.DataFrame({'Dates': dates, 'Predictions': final_predictions})
